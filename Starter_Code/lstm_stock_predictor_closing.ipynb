{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Stock Predictor Using Closing Prices\n",
    "\n",
    "In this notebook, you will build and train a custom LSTM RNN that uses a 10 day window of Bitcoin closing prices to predict the 11th day closing price. \n",
    "\n",
    "You will need to:\n",
    "\n",
    "1. Prepare the data for training and testing\n",
    "2. Build and train a custom LSTM RNN\n",
    "3. Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, you will need to prepare the training and testing data for the model. The model will use a rolling 10 day window to predict the 11th day closing price.\n",
    "\n",
    "You will need to:\n",
    "1. Use the `window_data` function to generate the X and y values for the model.\n",
    "2. Split the data into 70% training and 30% testing\n",
    "3. Apply the MinMaxScaler to the X and y values\n",
    "4. Reshape the X_train and X_test data for the model. Note: The required input format for the LSTM is:\n",
    "\n",
    "```python\n",
    "reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hvplot\n",
      "  Using cached hvplot-0.7.3-py2.py3-none-any.whl (3.1 MB)\n",
      "Requirement already satisfied: bokeh>=1.0.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from hvplot) (2.4.1)\n",
      "Collecting holoviews>=1.11.0\n",
      "  Using cached holoviews-1.14.8-py2.py3-none-any.whl (4.3 MB)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from hvplot) (1.20.3)\n",
      "Requirement already satisfied: pandas in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from hvplot) (1.3.4)\n",
      "Collecting colorcet>=2\n",
      "  Using cached colorcet-3.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (5.4.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (21.0)\n",
      "Requirement already satisfied: tornado>=5.1 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (6.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (8.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (3.10.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bokeh>=1.0.0->hvplot) (2.11.3)\n",
      "Collecting pyct>=0.4.4\n",
      "  Using cached pyct-0.4.8-py2.py3-none-any.whl (15 kB)\n",
      "Collecting param>=1.7.0\n",
      "  Using cached param-1.12.0-py2.py3-none-any.whl (85 kB)\n",
      "Collecting pyviz-comms>=0.7.4\n",
      "  Using cached pyviz_comms-2.1.0-py2.py3-none-any.whl (40 kB)\n",
      "Collecting panel>=0.8.0\n",
      "  Downloading panel-0.12.7-py2.py3-none-any.whl (12.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from Jinja2>=2.9->bokeh>=1.0.0->hvplot) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from packaging>=16.8->bokeh>=1.0.0->hvplot) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from pandas->hvplot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from pandas->hvplot) (2021.3)\n",
      "Requirement already satisfied: setuptools<61,>=42 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (58.0.4)\n",
      "Collecting markdown\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: bleach in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (4.0.0)\n",
      "Requirement already satisfied: tqdm>=4.48.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (4.62.3)\n",
      "Requirement already satisfied: requests in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from panel>=0.8.0->holoviews>=1.11.0->hvplot) (2.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->hvplot) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from bleach->panel>=0.8.0->holoviews>=1.11.0->hvplot) (0.5.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from markdown->panel>=0.8.0->holoviews>=1.11.0->hvplot) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown->panel>=0.8.0->holoviews>=1.11.0->hvplot) (3.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests->panel>=0.8.0->holoviews>=1.11.0->hvplot) (2021.10.8)\n",
      "Installing collected packages: param, pyviz-comms, pyct, markdown, panel, colorcet, holoviews, hvplot\n",
      "Successfully installed colorcet-3.0.0 holoviews-1.14.8 hvplot-0.7.3 markdown-3.3.6 panel-0.12.7 param-1.12.0 pyct-0.4.8 pyviz-comms-2.1.0\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-macosx_10_14_x86_64.whl (217.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 217.5 MB 29.2 MB/s eta 0:00:01 | 81.7 MB 4.0 MB/s eta 0:00:34\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: setuptools in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 95.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-macosx_10_10_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 96.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp39-cp39-macosx_10_9_x86_64.whl (961 kB)\n",
      "\u001b[K     |████████████████████████████████| 961 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/enriquebriceno/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=edd3d50cc372865e60540f03db5d38cdf7ebf34b71dd614780a2b9aa1a61a29f\n",
      "  Stored in directory: /Users/enriquebriceno/Library/Caches/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install hvplot\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mq/snyf56_s1w30tdmywbnsp0400000gn/T/ipykernel_74977/3705894443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the historical closing prices for Bitcoin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'btc_historic.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Close'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mq/snyf56_s1w30tdmywbnsp0400000gn/T/ipykernel_74977/1670668055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Join the data into a single DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inner\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mq/snyf56_s1w30tdmywbnsp0400000gn/T/ipykernel_74977/964094849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split = int(.7*len(X))\n",
    "X_train = X[:split-1]\n",
    "X_test = X[split:]\n",
    "y_train = y[:split-1]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "scaler.fit(y)\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the LSTM RNN\n",
    "\n",
    "In this section, you will design a custom LSTM RNN and fit (train) it using the training data.\n",
    "\n",
    "You will need to:\n",
    "1. Define the model architecture\n",
    "2. Compile the model\n",
    "3. Fit the model to the training data\n",
    "\n",
    "### Hints:\n",
    "You will want to use the same model architecture and random seed for both notebooks. This is necessary to accurately compare the performance of the FNG model vs the closing price model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mq/snyf56_s1w30tdmywbnsp0400000gn/T/ipykernel_74834/1789419415.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnumber_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdropout_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model. \n",
    "# The return sequences need to be set to True if you are adding additional LSTM layers, but \n",
    "# You don't have to do this for the final layer. \n",
    "# Note: The dropouts help prevent overfitting\n",
    "# Note: The input shape is the number of time steps and the number of indicators\n",
    "# Note: Batching inputs has a different input shape of Samples/TimeSteps/Features\n",
    "\n",
    "model = Sequential()\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2 \n",
    "\n",
    "#layer1\n",
    "\n",
    "model.add(LSTM(units=number_units, return_sequences = True, input_shape=(X_train.shape[1],1)))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Layer2\n",
    "\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Layer3\n",
    "\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "\n",
    "#Output layer\n",
    "\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 30)            3840      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 30)            7320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30)                7320      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 18,511\n",
      "Trainable params: 18,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0276\n",
      "Epoch 2/10\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0241\n",
      "Epoch 3/10\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0290\n",
      "Epoch 4/10\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0282\n",
      "Epoch 5/10\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0246\n",
      "Epoch 6/10\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0230\n",
      "Epoch 7/10\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0226\n",
      "Epoch 8/10\n",
      "371/371 [==============================] - 2s 6ms/step - loss: 0.0198\n",
      "Epoch 9/10\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0199\n",
      "Epoch 10/10\n",
      "371/371 [==============================] - 2s 5ms/step - loss: 0.0184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x287d0029248>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "# Use at least 10 epochs\n",
    "# Do not shuffle the data\n",
    "# Experiement with the batch size, but a smaller batch size is recommended\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "In this section, you will evaluate the model using the test data. \n",
    "\n",
    "You will need to:\n",
    "1. Evaluate the model using the `X_test` and `y_test` data.\n",
    "2. Use the X_test data to make predictions\n",
    "3. Create a DataFrame of Real (y_test) vs predicted values. \n",
    "4. Plot the Real vs predicted values as a line chart\n",
    "\n",
    "### Hints\n",
    "Remember to apply the `inverse_transform` function to the predicted and y_test values to recover the actual closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.048721764236688614"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = y_test_scaler.inverse_transform(predicted)\n",
    "real_prices = y_test_scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>3924.239990</td>\n",
       "      <td>4248.814941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-21</th>\n",
       "      <td>3974.050049</td>\n",
       "      <td>4270.220703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-22</th>\n",
       "      <td>3937.040039</td>\n",
       "      <td>4296.877441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-23</th>\n",
       "      <td>3983.530029</td>\n",
       "      <td>4322.457520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-24</th>\n",
       "      <td>4149.089844</td>\n",
       "      <td>4345.416504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Real    Predicted\n",
       "2019-02-20  3924.239990  4248.814941\n",
       "2019-02-21  3974.050049  4270.220703\n",
       "2019-02-22  3937.040039  4296.877441\n",
       "2019-02-23  3983.530029  4322.457520\n",
       "2019-02-24  4149.089844  4345.416504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Real\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = df.index[-len(real_prices): ]) \n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='1001'>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"6fa4249d-69c9-490e-beb0-fa767036f181\" data-root-id=\"1001\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  function embed_document(root) {\n",
       "  var docs_json = {\"5f8c398a-a52e-480c-84f5-cbfe0735843e\":{\"roots\":{\"references\":[{\"attributes\":{\"mantissas\":[1,2,5],\"max_interval\":500.0,\"num_minor_ticks\":0},\"id\":\"1055\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"days\":[1,4,7,10,13,16,19,22,25,28]},\"id\":\"1059\",\"type\":\"DaysTicker\"},{\"attributes\":{},\"id\":\"1026\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"num_minor_ticks\":5,\"tickers\":[{\"id\":\"1055\"},{\"id\":\"1056\"},{\"id\":\"1057\"},{\"id\":\"1058\"},{\"id\":\"1059\"},{\"id\":\"1060\"},{\"id\":\"1061\"},{\"id\":\"1062\"},{\"id\":\"1063\"},{\"id\":\"1064\"},{\"id\":\"1065\"},{\"id\":\"1066\"}]},\"id\":\"1017\",\"type\":\"DatetimeTicker\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1070\",\"type\":\"Selection\"},{\"attributes\":{\"label\":{\"value\":\"Predicted\"},\"renderers\":[{\"id\":\"1075\"}]},\"id\":\"1097\",\"type\":\"LegendItem\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer01562\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1002\",\"type\":\"Spacer\"},{\"attributes\":{\"base\":24,\"mantissas\":[1,2,4,6,8,12],\"max_interval\":43200000.0,\"min_interval\":3600000.0,\"num_minor_ticks\":0},\"id\":\"1057\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{},\"id\":\"1025\",\"type\":\"PanTool\"},{\"attributes\":{\"source\":{\"id\":\"1041\"}},\"id\":\"1048\",\"type\":\"CDSView\"},{\"attributes\":{\"data\":{\"Variable\":[\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\",\"Predicted\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkI=\",\"dtype\":\"float64\",\"shape\":[100]},\"value\":{\"__ndarray__\":\"hcaERcRxhUUFR4ZFqROHRVXLh0UHk4hF6vWIRff+iEWBx4hFknWIRUwciEXo0odF/Z+HRdx6h0VtRodF8CyHRb07h0X/XIdFDISHRWe9h0WQ/odF0iyIRQVHiEWuT4hF3EyIRd1NiEUdd4hFgbiIRUn9iEUVQolFg42JRYfHiUW+6YlFs/qJRYH8iUUj4IlFYLKJRWigiUXlqolFHtyJRVkpikUXgIpFDtqKRUEKjEUJB45FgkuQRUGQkkWhm5RF1niWRRUvmEXgkplF3LmaRR9Wm0VpbptFR0ybRcUqm0Wj7ZpFbtSaRY7nmkX7LZtFYJibRYsPnEUgiJxFrwCdRR6hnUX3Pp5FUnSeRTBNnkUL+J1FXqCdRZNPnUX6Kp1FBD6dRfSUnUWDYp5FwZ+fRdv/oEUILKJFjCejRVokpEX7UqVFscmmRXdbqUVeY6xFz02wRfjNtEVjgLlFJnq9RWfrv0Xi5MBFpNzBRUHbwkU4osNFyAXERRwYxEXpSsRFuK3ERZH9xUUOBshFWCzKRQ==\",\"dtype\":\"float32\",\"shape\":[100]}},\"selected\":{\"id\":\"1070\"},\"selection_policy\":{\"id\":\"1119\"}},\"id\":\"1069\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"click_policy\":\"mute\",\"items\":[{\"id\":\"1068\"},{\"id\":\"1097\"}],\"location\":[0,0],\"title\":\"Variable\"},\"id\":\"1067\",\"type\":\"Legend\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1045\",\"type\":\"Line\"},{\"attributes\":{\"source\":{\"id\":\"1069\"}},\"id\":\"1076\",\"type\":\"CDSView\"},{\"attributes\":{\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1072\",\"type\":\"Line\"},{\"attributes\":{\"label\":{\"value\":\"Real\"},\"renderers\":[{\"id\":\"1047\"}]},\"id\":\"1068\",\"type\":\"LegendItem\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1073\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,4,8]},\"id\":\"1064\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"axis\":{\"id\":\"1020\"},\"dimension\":1,\"grid_line_color\":null,\"ticker\":null},\"id\":\"1023\",\"type\":\"Grid\"},{\"attributes\":{\"data_source\":{\"id\":\"1041\"},\"glyph\":{\"id\":\"1044\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1046\"},\"nonselection_glyph\":{\"id\":\"1045\"},\"selection_glyph\":null,\"view\":{\"id\":\"1048\"}},\"id\":\"1047\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1066\",\"type\":\"YearsTicker\"},{\"attributes\":{\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1044\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,6]},\"id\":\"1065\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"overlay\":{\"id\":\"1029\"}},\"id\":\"1027\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#ff7e0e\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1074\",\"type\":\"Line\"},{\"attributes\":{\"margin\":[5,5,5,5],\"name\":\"HSpacer01563\",\"sizing_mode\":\"stretch_width\"},\"id\":\"1274\",\"type\":\"Spacer\"},{\"attributes\":{\"data_source\":{\"id\":\"1069\"},\"glyph\":{\"id\":\"1072\"},\"hover_glyph\":null,\"muted_glyph\":{\"id\":\"1074\"},\"nonselection_glyph\":{\"id\":\"1073\"},\"selection_glyph\":null,\"view\":{\"id\":\"1076\"}},\"id\":\"1075\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1028\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1096\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"months\":[0,1,2,3,4,5,6,7,8,9,10,11]},\"id\":\"1062\",\"type\":\"MonthsTicker\"},{\"attributes\":{\"line_alpha\":0.2,\"line_color\":\"#1f77b3\",\"line_width\":2,\"x\":{\"field\":\"index\"},\"y\":{\"field\":\"value\"}},\"id\":\"1046\",\"type\":\"Line\"},{\"attributes\":{\"months\":[0,2,4,6,8,10]},\"id\":\"1063\",\"type\":\"MonthsTicker\"},{\"attributes\":{},\"id\":\"1040\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"days\":[1,15]},\"id\":\"1061\",\"type\":\"DaysTicker\"},{\"attributes\":{\"end\":1559174400000.0,\"reset_end\":1559174400000.0,\"reset_start\":1550620800000.0,\"start\":1550620800000.0,\"tags\":[[[\"index\",\"index\",null]]]},\"id\":\"1003\",\"type\":\"Range1d\"},{\"attributes\":{\"axis_label\":\"\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1038\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"DatetimeAxis\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1029\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"text\":\"\",\"text_color\":{\"value\":\"black\"},\"text_font_size\":{\"value\":\"12pt\"}},\"id\":\"1008\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{\"base\":60,\"mantissas\":[1,2,5,10,15,20,30],\"max_interval\":1800000.0,\"min_interval\":1000.0,\"num_minor_ticks\":0},\"id\":\"1056\",\"type\":\"AdaptiveTicker\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1005\"},{\"id\":\"1024\"},{\"id\":\"1025\"},{\"id\":\"1026\"},{\"id\":\"1027\"},{\"id\":\"1028\"}]},\"id\":\"1030\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis_label\":\"\",\"bounds\":\"auto\",\"formatter\":{\"id\":\"1040\"},\"major_label_orientation\":\"horizontal\",\"ticker\":{\"id\":\"1021\"}},\"id\":\"1020\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1012\",\"type\":\"LinearScale\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"grid_line_color\":null,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{\"callback\":null,\"formatters\":{\"@{index}\":\"datetime\"},\"renderers\":[{\"id\":\"1047\"},{\"id\":\"1075\"}],\"tags\":[\"hv_created\"],\"tooltips\":[[\"Variable\",\"@{Variable}\"],[\"index\",\"@{index}{%F %T}\"],[\"value\",\"@{value}\"]]},\"id\":\"1005\",\"type\":\"HoverTool\"},{\"attributes\":{},\"id\":\"1038\",\"type\":\"DatetimeTickFormatter\"},{\"attributes\":{\"data\":{\"Variable\":[\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\",\"Real\"],\"index\":{\"__ndarray__\":\"AABAO4OQdkIAAACh1ZB2QgAAwAYokXZCAACAbHqRdkIAAEDSzJF2QgAAADgfknZCAADAnXGSdkIAAIADxJJ2QgAAQGkWk3ZCAAAAz2iTdkIAAMA0u5N2QgAAgJoNlHZCAABAAGCUdkIAAABmspR2QgAAwMsElXZCAACAMVeVdkIAAECXqZV2QgAAAP37lXZCAADAYk6WdkIAAIDIoJZ2QgAAQC7zlnZCAAAAlEWXdkIAAMD5l5d2QgAAgF/ql3ZCAABAxTyYdkIAAAArj5h2QgAAwJDhmHZCAACA9jOZdkIAAEBchpl2QgAAAMLYmXZCAADAJyuadkIAAICNfZp2QgAAQPPPmnZCAAAAWSKbdkIAAMC+dJt2QgAAgCTHm3ZCAABAihmcdkIAAADwa5x2QgAAwFW+nHZCAACAuxCddkIAAEAhY512QgAAAIe1nXZCAADA7AeedkIAAIBSWp52QgAAQLisnnZCAAAAHv+edkIAAMCDUZ92QgAAgOmjn3ZCAABAT/afdkIAAAC1SKB2QgAAwBqboHZCAACAgO2gdkIAAEDmP6F2QgAAAEySoXZCAADAseShdkIAAIAXN6J2QgAAQH2JonZCAAAA49uidkIAAMBILqN2QgAAgK6Ao3ZCAABAFNOjdkIAAAB6JaR2QgAAwN93pHZCAACARcqkdkIAAECrHKV2QgAAABFvpXZCAADAdsGldkIAAIDcE6Z2QgAAQEJmpnZCAAAAqLimdkIAAMANC6d2QgAAgHNdp3ZCAABA2a+ndkIAAAA/Aqh2QgAAwKRUqHZCAACACqeodkIAAEBw+ah2QgAAANZLqXZCAADAO56pdkIAAICh8Kl2QgAAQAdDqnZCAAAAbZWqdkIAAMDS56p2QgAAgDg6q3ZCAABAnoyrdkIAAAAE36t2QgAAwGkxrHZCAACAz4OsdkIAAEA11qx2QgAAAJsorXZCAADAAHutdkIAAIBmza12QgAAQMwfrnZCAAAAMnKudkIAAMCXxK52QgAAgP0Wr3ZCAABAY2mvdkIAAADJu692QgAAwC4OsHZCAACAlGCwdkI=\",\"dtype\":\"float64\",\"shape\":[100]},\"value\":{\"__ndarray__\":\"vCL433qorkBmxAWgGQyvQCHn/X8Uwq5A3gn2Xw8fr0C+MQQAFzWwQGS1+X89d61ARN0HIAULrkCcSgaAwtOtQCP2CaBw7a1AZLX5f73erUB3RfC/9e6tQFZe8j/hBa5AqqENwJ7IrUDdCfZfjyatQAIPDCBcRK5Ad0Xwv/VFrkAg2PFfOFWuQIm6D0AKOK5AvCL433rXrkCHqwMgrrOuQOEnDqDHRa5A/vDz3yNhrkBWXvI/4UyuQFZe8j/hUq5AQs77/yiurkBE3QcgBXavQAAAAAAAPK9AyogLQLMpr0DgJw6gR3CvQAAAAACAsa9AAg8MINw5r0CHqwMgrkGvQN8YAoBrTq9AH9jxXzg0r0BmxAWgGamuQCP2CaBwzK5Ad0Xwv/Wbr0CaO/pf5oivQE4lA0BhD7BATiUDQCEWsEArL/mfsBCwQHpU/N9RN7BAhqsDIO4qs0C+MQQAl3CzQAtI+x9cMbNAvSL43zq3s0ABAAAAQMGzQELO+/8oUbRAvjEEABeutEAtPgXATFG0QGXEBaCZxrRA1dAGYI+4s0AAAAAAgNmzQELO+/+o2LNAvjEEAJcttEBE3QcgRa2zQNXQBmDPXLRAm0oGgEJ0tED/////v6m0QOlg/Z+Hr7RAhasDIC7OtEBktfl/vbm0QN8YAoCrErVAZcQFoBmjtUAh5/1/lE61QN8YAoCrKrRAvjEEABdytEC8Ivjfem20QNPB+j9zmLRAbwwBwPV1tED1twTgo+a0QJHz/j+KDbVAF58CYLh8tUBOJQNAYXm2QCHn/X8U0LZA9bcE4COitkDfGAKAK3S2QHlU/N+Ru7ZAbwwBwLVut0BvDAHA9Ru4QJHz/j9K1rhACkj7H1wXvEBPJQNAoUG7QApI+x9cfr5ATSUDQCEsv0Ah5/1/1Pe/QApI+x8cwr5AbgwBwPXLvEAh5/1/FGK8QHpU/N+RAMBAkfP+P0o+v0CHqwMg7gu/QPa3BODjyr1A/////3/EvkCaO/pfZjy/QE4lA0Ahe79A3xgCgB0LwUBvDAHAlSjBQLLa/L9sB8FA6WD9n0fswEA=\",\"dtype\":\"float64\",\"shape\":[100]}},\"selected\":{\"id\":\"1042\"},\"selection_policy\":{\"id\":\"1096\"}},\"id\":\"1041\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1119\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"align\":null,\"below\":[{\"id\":\"1016\"}],\"center\":[{\"id\":\"1019\"},{\"id\":\"1023\"}],\"left\":[{\"id\":\"1020\"}],\"margin\":null,\"min_border_bottom\":10,\"min_border_left\":10,\"min_border_right\":10,\"min_border_top\":10,\"plot_height\":300,\"plot_width\":700,\"renderers\":[{\"id\":\"1047\"},{\"id\":\"1075\"}],\"right\":[{\"id\":\"1067\"}],\"sizing_mode\":\"fixed\",\"title\":{\"id\":\"1008\"},\"toolbar\":{\"id\":\"1030\"},\"x_range\":{\"id\":\"1003\"},\"x_scale\":{\"id\":\"1012\"},\"y_range\":{\"id\":\"1004\"},\"y_scale\":{\"id\":\"1014\"}},\"id\":\"1007\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"end\":9290.558911299999,\"reset_end\":9290.558911299999,\"reset_start\":3225.8910397,\"start\":3225.8910397,\"tags\":[[[\"value\",\"value\",null]]]},\"id\":\"1004\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1042\",\"type\":\"Selection\"},{\"attributes\":{\"days\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]},\"id\":\"1058\",\"type\":\"DaysTicker\"},{\"attributes\":{\"days\":[1,8,15,22]},\"id\":\"1060\",\"type\":\"DaysTicker\"},{\"attributes\":{\"children\":[{\"id\":\"1002\"},{\"id\":\"1007\"},{\"id\":\"1274\"}],\"margin\":[0,0,0,0],\"name\":\"Row01558\",\"tags\":[\"embedded\"]},\"id\":\"1001\",\"type\":\"Row\"}],\"root_ids\":[\"1001\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.2\"}};\n",
       "  var render_items = [{\"docid\":\"5f8c398a-a52e-480c-84f5-cbfe0735843e\",\"root_ids\":[\"1001\"],\"roots\":{\"1001\":\"6fa4249d-69c9-490e-beb0-fa767036f181\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "  }\n",
       "if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       ":NdOverlay   [Variable]\n",
       "   :Curve   [index]   (value)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "1001"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the real vs predicted values as a line chart\n",
    "from matplotlib import pyplot as plt    \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(stocks)\n",
    "fig.suptitle('Closing Price: Predicted verse Actual, Window 1', fontsize=10)\n",
    "plt.ylabel('Bitcoin Price')\n",
    "plt.savefig('closing1.png')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
